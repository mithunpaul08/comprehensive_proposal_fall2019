% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep
  bidirectional transformers for language understanding,'' \emph{arXiv preprint
  arXiv:1810.04805}, 2018.

\bibitem{sun2018improving}
K.~Sun, D.~Yu, D.~Yu, and C.~Cardie, ``Improving machine reading comprehension
  with general reading strategies,'' \emph{arXiv preprint arXiv:1810.13441},
  2018.

\bibitem{bohnet2018morphosyntactic}
B.~Bohnet, R.~McDonald, G.~Simoes, D.~Andor, E.~Pitler, and J.~Maynez,
  ``Morphosyntactic tagging with a meta-bilstm model over context sensitive
  token encodings,'' \emph{arXiv preprint arXiv:1805.08237}, 2018.

\bibitem{kim2018semantic}
S.~Kim, J.-H. Hong, I.~Kang, and N.~Kwak, ``Semantic sentence matching with
  densely-connected recurrent and co-attentive information,'' \emph{arXiv
  preprint arXiv:1805.11360}, 2018.

\bibitem{baird2017talos}
S.~Baird, D.~Sibley, and Y.~Pan, ``Talos targets disinformation with fake news
  challenge victory,'' \emph{Fake News Challenge}, 2017.

\bibitem{nie2018combining}
Y.~Nie, H.~Chen, and M.~Bansal, ``Combining fact extraction and verification
  with neural semantic matching networks,'' \emph{arXiv preprint
  arXiv:1811.07039}, 2018.

\bibitem{dagan2013recognizing}
I.~Dagan, D.~Roth, M.~Sammons, and F.~M. Zanzotto, ``Recognizing textual
  entailment: Models and applications,'' \emph{Synthesis Lectures on Human
  Language Technologies}, vol.~6, no.~4, pp. 1--220, 2013.

\bibitem{thorne2018fever}
J.~Thorne, A.~Vlachos, C.~Christodoulopoulos, and A.~Mittal, ``Fever: a
  large-scale dataset for fact extraction and verification,'' \emph{arXiv
  preprint arXiv:1803.05355}, 2018.

\bibitem{fyodorov2000natural}
Y.~Fyodorov, Y.~Winter, and N.~Francez, ``A natural logic inference system,''
  in \emph{Proceedings of the 2nd Workshop on Inference in Computational
  Semantics (ICoS-2)}.\hskip 1em plus 0.5em minus 0.4em\relax Citeseer, 2000.

\bibitem{condoravdi2003entailment}
C.~Condoravdi, D.~Crouch, V.~De~Paiva, R.~Stolle, and D.~G. Bobrow,
  ``Entailment, intensionality and text understanding,'' in \emph{Proceedings
  of the HLT-NAACL 2003 workshop on Text meaning}, 2003, pp. 38--45.

\bibitem{bos2005recognising}
J.~Bos and K.~Markert, ``Recognising textual entailment with logical
  inference,'' in \emph{Proceedings of the conference on Human Language
  Technology and Empirical Methods in Natural Language Processing}.\hskip 1em
  plus 0.5em minus 0.4em\relax Association for Computational Linguistics, 2005,
  pp. 628--635.

\bibitem{maccartney2009extended}
B.~MacCartney and C.~D. Manning, ``An extended model of natural logic,'' in
  \emph{Proceedings of the eighth international conference on computational
  semantics}.\hskip 1em plus 0.5em minus 0.4em\relax Association for
  Computational Linguistics, 2009, pp. 140--156.

\bibitem{gururangan2018annotation}
S.~Gururangan, S.~Swayamdipta, O.~Levy, R.~Schwartz, S.~R. Bowman, and N.~A.
  Smith, ``Annotation artifacts in natural language inference data,''
  \emph{arXiv preprint arXiv:1803.02324}, 2018.

\bibitem{bowman2015large}
S.~R. Bowman, G.~Angeli, C.~Potts, and C.~D. Manning, ``A large annotated
  corpus for learning natural language inference,'' \emph{arXiv preprint
  arXiv:1508.05326}, 2015.

\bibitem{williams2017broad}
A.~Williams, N.~Nangia, and S.~R. Bowman, ``A broad-coverage challenge corpus
  for sentence understanding through inference,'' \emph{arXiv preprint
  arXiv:1704.05426}, 2017.

\bibitem{pomerleau2017fake}
D.~Pomerleau and D.~Rao, ``Fake news challenge,'' 2017.

\bibitem{poliak2018hypothesis}
A.~Poliak, J.~Naradowsky, A.~Haldar, R.~Rudinger, and B.~Van~Durme,
  ``Hypothesis only baselines in natural language inference,'' \emph{arXiv
  preprint arXiv:1805.01042}, 2018.

\bibitem{schuster2019towards}
T.~Schuster, D.~J. Shah, Y.~J.~S. Yeo, D.~Filizzola, E.~Santus, and
  R.~Barzilay, ``Towards debiasing fact verification models,'' \emph{arXiv
  preprint arXiv:1908.05267}, 2019.

\bibitem{emnlp2019sandeep}
\BIBentryALTinterwordspacing
S.~Suntwal, M.~Paul, R.~Sharp, and M.~Surdeanu, ``On the importance of
  delexicalization for fact verification,'' in \emph{Proceedings of the 2019
  Conference on Empirical Methods in Natural Language Processing and the 9th
  International Joint Conference on Natural Language Processing, (Short
  Papers)}.\hskip 1em plus 0.5em minus 0.4em\relax Hong Kong: Association for
  Computational Linguistics, November 2019. [Online]. Available:
  \url{http://clulab.cs.arizona.edu/papers/emnlp_2019_masking_suntwal_etal.pdf}
\BIBentrySTDinterwordspacing

\bibitem{zeman2008cross}
D.~Zeman and P.~Resnik, ``Cross-language parser adaptation between related
  languages,'' in \emph{Proceedings of the IJCNLP-08 Workshop on NLP for Less
  Privileged Languages}, 2008.

\bibitem{peyrard2019simple}
M.~Peyrard, ``A simple theoretical model of importance for summarization,'' in
  \emph{Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, 2019, pp. 1059--1073.

\bibitem{parikh2016decomposable}
A.~P. Parikh, O.~T{\"a}ckstr{\"o}m, D.~Das, and J.~Uszkoreit, ``A decomposable
  attention model for natural language inference,'' \emph{arXiv preprint
  arXiv:1606.01933}, 2016.

\bibitem{chen2016enhanced}
Q.~Chen, X.~Zhu, Z.~Ling, S.~Wei, H.~Jiang, and D.~Inkpen, ``Enhanced lstm for
  natural language inference,'' \emph{arXiv preprint arXiv:1609.06038}, 2016.

\bibitem{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly
  learning to align and translate,'' \emph{arXiv preprint arXiv:1409.0473},
  2014.

\bibitem{manning2014stanford}
C.~Manning, M.~Surdeanu, J.~Bauer, J.~Finkel, S.~Bethard, and D.~McClosky,
  ``The stanford corenlp natural language processing toolkit,'' in
  \emph{Proceedings of 52nd annual meeting of the association for computational
  linguistics: system demonstrations}, 2014, pp. 55--60.

\bibitem{ciaramita2003supersense}
M.~Ciaramita and M.~Johnson, ``Supersense tagging of unknown nouns in
  wordnet,'' in \emph{Proceedings of the 2003 conference on Empirical methods
  in natural language processing}.\hskip 1em plus 0.5em minus 0.4em\relax
  Association for Computational Linguistics, 2003, pp. 168--175.

\bibitem{pennington2014glove}
J.~Pennington, R.~Socher, and C.~Manning, ``Glove: Global vectors for word
  representation,'' in \emph{Proceedings of the 2014 conference on empirical
  methods in natural language processing (EMNLP)}, 2014, pp. 1532--1543.

\bibitem{miller1990introduction}
G.~A. Miller, R.~Beckwith, C.~Fellbaum, D.~Gross, and K.~J. Miller,
  ``Introduction to wordnet: An on-line lexical database,'' \emph{International
  journal of lexicography}, vol.~3, no.~4, pp. 235--244, 1990.

\end{thebibliography}
