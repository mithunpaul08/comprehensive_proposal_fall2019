% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep
  bidirectional transformers for language understanding,'' \emph{arXiv preprint
  arXiv:1810.04805}, 2018.

\bibitem{sun2018improving}
K.~Sun, D.~Yu, D.~Yu, and C.~Cardie, ``Improving machine reading comprehension
  with general reading strategies,'' \emph{arXiv preprint arXiv:1810.13441},
  2018.

\bibitem{bohnet2018morphosyntactic}
B.~Bohnet, R.~McDonald, G.~Simoes, D.~Andor, E.~Pitler, and J.~Maynez,
  ``Morphosyntactic tagging with a meta-bilstm model over context sensitive
  token encodings,'' \emph{arXiv preprint arXiv:1805.08237}, 2018.

\bibitem{kim2018semantic}
S.~Kim, J.-H. Hong, I.~Kang, and N.~Kwak, ``Semantic sentence matching with
  densely-connected recurrent and co-attentive information,'' \emph{arXiv
  preprint arXiv:1805.11360}, 2018.

\bibitem{baird2017talos}
S.~Baird, D.~Sibley, and Y.~Pan, ``Talos targets disinformation with fake news
  challenge victory,'' \emph{Fake News Challenge}, 2017.

\bibitem{nie2018combining}
Y.~Nie, H.~Chen, and M.~Bansal, ``Combining fact extraction and verification
  with neural semantic matching networks,'' \emph{arXiv preprint
  arXiv:1811.07039}, 2018.

\bibitem{dagan2013recognizing}
I.~Dagan, D.~Roth, M.~Sammons, and F.~M. Zanzotto, ``Recognizing textual
  entailment: Models and applications,'' \emph{Synthesis Lectures on Human
  Language Technologies}, vol.~6, no.~4, pp. 1--220, 2013.

\bibitem{thorne2018fever}
J.~Thorne, A.~Vlachos, C.~Christodoulopoulos, and A.~Mittal, ``Fever: a
  large-scale dataset for fact extraction and verification,'' \emph{arXiv
  preprint arXiv:1803.05355}, 2018.

\bibitem{pomerleau2017fake}
D.~Pomerleau and D.~Rao, ``Fake news challenge,'' 2017.

\bibitem{parikh2016decomposable}
A.~P. Parikh, O.~T{\"a}ckstr{\"o}m, D.~Das, and J.~Uszkoreit, ``A decomposable
  attention model for natural language inference,'' \emph{arXiv preprint
  arXiv:1606.01933}, 2016.

\bibitem{zeman2008cross}
D.~Zeman and P.~Resnik, ``Cross-language parser adaptation between related
  languages,'' in \emph{Proceedings of the IJCNLP-08 Workshop on NLP for Less
  Privileged Languages}, 2008.

\bibitem{manning2014stanford}
C.~Manning, M.~Surdeanu, J.~Bauer, J.~Finkel, S.~Bethard, and D.~McClosky,
  ``The stanford corenlp natural language processing toolkit,'' in
  \emph{Proceedings of 52nd annual meeting of the association for computational
  linguistics: system demonstrations}, 2014, pp. 55--60.

\bibitem{ciaramita2003supersense}
M.~Ciaramita and M.~Johnson, ``Supersense tagging of unknown nouns in
  wordnet,'' in \emph{Proceedings of the 2003 conference on Empirical methods
  in natural language processing}.\hskip 1em plus 0.5em minus 0.4em\relax
  Association for Computational Linguistics, 2003, pp. 168--175.

\end{thebibliography}
